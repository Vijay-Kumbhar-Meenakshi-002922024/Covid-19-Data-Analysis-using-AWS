{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37706b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 #used to connect to aws services to work with it\n",
    "import pandas as pd\n",
    "from io import StringIO # to encode data in binary form\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123f6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY =\"AKIAYTHDC6DYXGKIVXAX\"\n",
    "AWS_SECRET_KEY = \"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\"\n",
    "AWS_REGION = \"us-east-1\"\n",
    "SCHEMA_NAME = \"covid_dataset\"\n",
    "S3_STAGING_DIR = \"s3://meenakshi-test-bucket/output/\"\n",
    "S3_BUCKET_NAME = \"meenakshi-test-bucket\"\n",
    "S3_OUTPUT_DIRECTORY = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9738d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to athena and query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6dbcf48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "athena_client = boto3.client(\n",
    "                \"athena\",\n",
    "                aws_access_key_id = AWS_ACCESS_KEY,\n",
    "                aws_secret_access_key = AWS_SECRET_KEY,\n",
    "                region_name = AWS_REGION,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e5a0814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes the dictionary, goes to athena runs query and store data in s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0fb2dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = athena_client.start_query_execution(\n",
    "#             QueryString =\"SELECT * FROM enigma_jhud\",\n",
    "#             QueryExecutionContext = {\"Database\":SCHEMA_NAME},\n",
    "#             ResultConfiguration={\n",
    "#                 \"OutputLocation\": S3_STAGING_DIR,\n",
    "#                 \"EncryptionConfiguration\": {\"EncryptionOption\":\"SSE_S3\"},\n",
    "#                 },\n",
    "#             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0c55a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: enigma_jhud, QueryExecutionId: bf8bffb3-d735-47be-931d-c43a27ecd56c\n",
      "Table: nytimes_data_in_usa_countyus_county, QueryExecutionId: 2e1e6b30-acfa-46b0-b38a-107c9e10a162\n",
      "Table: covid_19_testing_data_states_dailystates_daily, QueryExecutionId: e1693f51-c3f6-4d0d-8406-9ea02ae94663\n",
      "Table: covid_19_testing_data_us_dailyus_daily, QueryExecutionId: 00b92f2a-7e74-4b50-be3b-c54078d4dfd9\n",
      "Table: covid_19_testing_data_us_total_latestus_total_latest, QueryExecutionId: f3bbe0a8-8634-4f0f-8b91-9dbb2ae70f58\n",
      "Table: nytimes_data_in_usaus_states, QueryExecutionId: e2e27bde-0720-4cfa-9b8a-c2555e5fd37c\n",
      "Table: rearc_usa_hospital_beds, QueryExecutionId: 327dd551-fe27-4485-924c-26463e7c6f39\n",
      "Table: static_datasets_countrycodecountrycode, QueryExecutionId: ff6d4542-223a-430f-8978-c4ac18878b51\n",
      "Table: static_datasets_countypopulationcountypopulation, QueryExecutionId: 955db721-f204-47b1-b3a4-5053df0fbc20\n",
      "Table: static_datasets_state_abvstate_abv, QueryExecutionId: 49296c9e-8e9c-471c-808b-718434d51cff\n"
     ]
    }
   ],
   "source": [
    "# table_names = [\"enigma_jhud\", \"nytimes_data_in_usa_countyus_county\",\"covid_19_testing_data_states_dailystates_daily\",\"covid_19_testing_data_us_dailyus_daily\",\"covid_19_testing_data_us_total_latestus_total_latest\",\"nytimes_data_in_usaus_states\",\"rearc_usa_hospital_beds\",\"static_datasets_countrycodecountrycode\",\"static_datasets_countypopulationcountypopulation\",\"static_datasets_state_abvstate_abv\"\n",
    "#         ]\n",
    "# query_execution_responses = []\n",
    "\n",
    "# for table_name in table_names:\n",
    "#     response = athena_client.start_query_execution(\n",
    "#         QueryString=f\"SELECT * FROM {table_name}\",\n",
    "#         QueryExecutionContext={\"Database\": SCHEMA_NAME},\n",
    "#         ResultConfiguration={\n",
    "#             \"OutputLocation\": S3_STAGING_DIR,\n",
    "#             \"EncryptionConfiguration\": {\"EncryptionOption\": \"SSE_S3\"},\n",
    "#         },\n",
    "#     )\n",
    "#     query_execution_responses.append(response)\n",
    "\n",
    "# # Print or handle the list of query execution responses\n",
    "# table_query_execution_dict = {table_names[i]: query_execution_responses[i]['QueryExecutionId'] for i in range(len(table_names))}\n",
    "\n",
    "# # Print or handle the table_query_execution_dict as needed\n",
    "# for table_name, query_execution_id in table_query_execution_dict.items():\n",
    "#     print(f\"Table: {table_name}, QueryExecutionId: {query_execution_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68590a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QueryExecutionId': '49296c9e-8e9c-471c-808b-718434d51cff',\n",
       " 'ResponseMetadata': {'RequestId': 'b02ddc3c-3950-4307-9256-78b711023c58',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Wed, 24 May 2023 19:40:50 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '59',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'b02ddc3c-3950-4307-9256-78b711023c58'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a364d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's3_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m full_file_name \u001b[38;5;241m=\u001b[39m file_name \u001b[38;5;241m+\u001b[39m file_extension\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Download the file from S3\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43ms3_client\u001b[49m\u001b[38;5;241m.\u001b[39mdownload_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeenakshi-test-bucket\u001b[39m\u001b[38;5;124m'\u001b[39m, s3_object_key, full_file_name)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile downloaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_file_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 's3_client' is not defined"
     ]
    }
   ],
   "source": [
    "# for i in range(len(table_names)):\n",
    "#     table_name = table_names[i]\n",
    "#     query_execution_id = query_execution_responses[i]['QueryExecutionId']\n",
    "\n",
    "#     query_execution_result = athena_client.get_query_execution(\n",
    "#         QueryExecutionId=query_execution_id\n",
    "#     )\n",
    "    \n",
    "#     s3_object_key = query_execution_result['QueryExecution']['ResultConfiguration']['OutputLocation']\n",
    "#     s3_object_key = s3_object_key.replace('s3://meenakshi-test-bucket/', '')\n",
    "    \n",
    "#     file_name = table_name\n",
    "#     file_extension = '.csv'\n",
    "#     full_file_name = file_name + file_extension\n",
    "    \n",
    "#     # Download the file from S3\n",
    "#     s3_client.download_file('meenakshi-test-bucket', s3_object_key, full_file_name)\n",
    "#     print(f\"File downloaded: {full_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe858d22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# exe_id = response['QueryExecutionId']\n",
    "# # Set up AWS credentials and region\n",
    "# # Configure AWS SDK\n",
    "# s3_client = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY, region_name=AWS_REGION)\n",
    "\n",
    "# # Retrieve query execution details (e.g., with AWS Glue or Amazon Athena)\n",
    "# # Replace `YOUR_QUERY_EXECUTION_ID` with the actual ID\n",
    "# query_execution_id = exe_id\n",
    "# query_execution_result = athena_client.get_query_execution(\n",
    "#     QueryExecutionId=query_execution_id\n",
    "# )\n",
    "\n",
    "# # Extract the S3 object key from the query execution details\n",
    "# s3_object_key = query_execution_result['QueryExecution']['ResultConfiguration']['OutputLocation']\n",
    "\n",
    "# # Remove the \"s3://\" prefix\n",
    "# s3_object_key = s3_object_key.replace('s3://meenakshi-test-bucket/', '')\n",
    "\n",
    "# print(s3_object_key)  # Output: meenakshi-test-bucket/output/4749a786-d9a1-430b-9a40-56e3f20fa20e.csv\n",
    "\n",
    "# file_name = exe_id\n",
    "# file_extension = '.csv'\n",
    "# full_file_name = file_name + file_extension\n",
    "# print(full_file_name)\n",
    "# # Download the file from S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77831b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "##s3_client.download_file('meenakshi-test-bucket', s3_object_key, full_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1ff16f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded: enigma_jhud.csv\n",
      "File downloaded: nytimes_data_in_usa_countyus_county.csv\n",
      "File downloaded: covid_19_testing_data_states_dailystates_daily.csv\n",
      "File downloaded: covid_19_testing_data_us_dailyus_daily.csv\n",
      "File downloaded: covid_19_testing_data_us_total_latestus_total_latest.csv\n",
      "File downloaded: nytimes_data_in_usaus_states.csv\n",
      "File downloaded: rearc_usa_hospital_beds.csv\n",
      "File downloaded: static_datasets_countrycodecountrycode.csv\n",
      "File downloaded: static_datasets_countypopulationcountypopulation.csv\n",
      "File downloaded: static_datasets_state_abvstate_abv.csv\n",
      "All files downloaded successfully.\n",
      "output/e7a661fb-cc90-4d05-a73d-a3e17ce4b434.csv\n",
      "output/e7a661fb-cc90-4d05-a73d-a3e17ce4b434.csv.metadata\n",
      "File deleted from S3: output/e7a661fb-cc90-4d05-a73d-a3e17ce4b434.csv\n",
      "File deleted from S3: output/e7a661fb-cc90-4d05-a73d-a3e17ce4b434.csv.metadata\n",
      "output/47bb4fd2-9415-4ec0-b5d0-17d92f3ccf95.csv\n",
      "output/47bb4fd2-9415-4ec0-b5d0-17d92f3ccf95.csv.metadata\n",
      "File deleted from S3: output/47bb4fd2-9415-4ec0-b5d0-17d92f3ccf95.csv\n",
      "File deleted from S3: output/47bb4fd2-9415-4ec0-b5d0-17d92f3ccf95.csv.metadata\n",
      "output/922abe4c-81d3-4d45-81e1-0acfec19798b.csv\n",
      "output/922abe4c-81d3-4d45-81e1-0acfec19798b.csv.metadata\n",
      "File deleted from S3: output/922abe4c-81d3-4d45-81e1-0acfec19798b.csv\n",
      "File deleted from S3: output/922abe4c-81d3-4d45-81e1-0acfec19798b.csv.metadata\n",
      "output/475e050f-e04b-4de3-aacb-61afbf0808ef.csv\n",
      "output/475e050f-e04b-4de3-aacb-61afbf0808ef.csv.metadata\n",
      "File deleted from S3: output/475e050f-e04b-4de3-aacb-61afbf0808ef.csv\n",
      "File deleted from S3: output/475e050f-e04b-4de3-aacb-61afbf0808ef.csv.metadata\n",
      "output/b7dd202a-574b-4a82-bde1-22dbf95b8080.csv\n",
      "output/b7dd202a-574b-4a82-bde1-22dbf95b8080.csv.metadata\n",
      "File deleted from S3: output/b7dd202a-574b-4a82-bde1-22dbf95b8080.csv\n",
      "File deleted from S3: output/b7dd202a-574b-4a82-bde1-22dbf95b8080.csv.metadata\n",
      "output/5bee7236-06a3-4e35-b0a4-45cea879b64a.csv\n",
      "output/5bee7236-06a3-4e35-b0a4-45cea879b64a.csv.metadata\n",
      "File deleted from S3: output/5bee7236-06a3-4e35-b0a4-45cea879b64a.csv\n",
      "File deleted from S3: output/5bee7236-06a3-4e35-b0a4-45cea879b64a.csv.metadata\n",
      "output/951d792c-1c5b-42a6-b039-1f8b56ec5717.csv\n",
      "output/951d792c-1c5b-42a6-b039-1f8b56ec5717.csv.metadata\n",
      "File deleted from S3: output/951d792c-1c5b-42a6-b039-1f8b56ec5717.csv\n",
      "File deleted from S3: output/951d792c-1c5b-42a6-b039-1f8b56ec5717.csv.metadata\n",
      "output/a3e95669-684d-4497-8260-8326555adb90.csv\n",
      "output/a3e95669-684d-4497-8260-8326555adb90.csv.metadata\n",
      "File deleted from S3: output/a3e95669-684d-4497-8260-8326555adb90.csv\n",
      "File deleted from S3: output/a3e95669-684d-4497-8260-8326555adb90.csv.metadata\n",
      "output/55c1967c-2e0e-435e-9f87-ca925f80b048.csv\n",
      "output/55c1967c-2e0e-435e-9f87-ca925f80b048.csv.metadata\n",
      "File deleted from S3: output/55c1967c-2e0e-435e-9f87-ca925f80b048.csv\n",
      "File deleted from S3: output/55c1967c-2e0e-435e-9f87-ca925f80b048.csv.metadata\n",
      "output/f1a92e10-7588-47b3-844a-95bbdba08d6a.csv\n",
      "output/f1a92e10-7588-47b3-844a-95bbdba08d6a.csv.metadata\n",
      "File deleted from S3: output/f1a92e10-7588-47b3-844a-95bbdba08d6a.csv\n",
      "File deleted from S3: output/f1a92e10-7588-47b3-844a-95bbdba08d6a.csv.metadata\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set up AWS credentials and region\n",
    "# Configure AWS SDK\n",
    "s3_client = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY, region_name=AWS_REGION)\n",
    "\n",
    "table_names = [\"enigma_jhud\", \"nytimes_data_in_usa_countyus_county\",\"covid_19_testing_data_states_dailystates_daily\",\"covid_19_testing_data_us_dailyus_daily\",\"covid_19_testing_data_us_total_latestus_total_latest\",\"nytimes_data_in_usaus_states\",\"rearc_usa_hospital_beds\",\"static_datasets_countrycodecountrycode\",\"static_datasets_countypopulationcountypopulation\",\"static_datasets_state_abvstate_abv\"]\n",
    "\n",
    "query_execution_responses = []\n",
    "\n",
    "for table_name in table_names:\n",
    "    response = athena_client.start_query_execution(\n",
    "        QueryString=f\"SELECT * FROM {table_name}\",\n",
    "        QueryExecutionContext={\"Database\": SCHEMA_NAME},\n",
    "        ResultConfiguration={\n",
    "            \"OutputLocation\": S3_STAGING_DIR,\n",
    "            \"EncryptionConfiguration\": {\"EncryptionOption\": \"SSE_S3\"},\n",
    "        },\n",
    "    )\n",
    "    query_execution_responses.append(response)\n",
    "\n",
    "all_files_downloaded = True  # Flag to check if all files are downloaded\n",
    "\n",
    "for i in range(len(table_names)):\n",
    "    table_name = table_names[i]\n",
    "    query_execution_id = query_execution_responses[i]['QueryExecutionId']\n",
    "\n",
    "    query_execution_result = athena_client.get_query_execution(\n",
    "        QueryExecutionId=query_execution_id\n",
    "    )\n",
    "    \n",
    "    s3_object_key = query_execution_result['QueryExecution']['ResultConfiguration']['OutputLocation']\n",
    "    s3_object_key = s3_object_key.replace('s3://meenakshi-test-bucket/', '')\n",
    "    \n",
    "    file_name = table_name\n",
    "    file_extension = '.csv'\n",
    "    full_file_name = file_name + file_extension\n",
    "    # Download the file from S3\n",
    "    s3_client.download_file('meenakshi-test-bucket', s3_object_key, full_file_name)\n",
    "    print(f\"File downloaded: {full_file_name}\")\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(full_file_name):\n",
    "        all_files_downloaded = False\n",
    "        break\n",
    "\n",
    "if all_files_downloaded:\n",
    "    print(\"All files downloaded successfully.\")\n",
    "    \n",
    "    # Delete the files from S3\n",
    "    for i in range(len(table_names)):\n",
    "        table_name = table_names[i]\n",
    "        query_execution_id = query_execution_responses[i]['QueryExecutionId']\n",
    "        file_name = query_execution_id + \".csv\"\n",
    "        file_metadata_name = query_execution_id + \".csv.metadata\"\n",
    "        s3_object_key = f\"output/{file_name}\"\n",
    "        s3_metadata_object_key = f\"output/{file_metadata_name}\"\n",
    "        print(s3_object_key)\n",
    "        print(s3_metadata_object_key)\n",
    "        s3_client.delete_object(Bucket='meenakshi-test-bucket', Key=s3_object_key)\n",
    "        s3_client.delete_object(Bucket='meenakshi-test-bucket', Key=s3_metadata_object_key)\n",
    "        print(f\"File deleted from S3: {s3_object_key}\")\n",
    "        print(f\"File deleted from S3: {s3_metadata_object_key}\")\n",
    "else:\n",
    "    print(\"Not all files were downloaded. Check the file download process.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "739d8caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file read: enigma_jhud.csv for table: enigma_jhud\n",
      "CSV file read: nytimes_data_in_usa_countyus_county.csv for table: nytimes_data_in_usa_countyus_county\n",
      "CSV file read: covid_19_testing_data_states_dailystates_daily.csv for table: covid_19_testing_data_states_dailystates_daily\n",
      "CSV file read: covid_19_testing_data_us_dailyus_daily.csv for table: covid_19_testing_data_us_dailyus_daily\n",
      "CSV file read: covid_19_testing_data_us_total_latestus_total_latest.csv for table: covid_19_testing_data_us_total_latestus_total_latest\n",
      "CSV file read: nytimes_data_in_usaus_states.csv for table: nytimes_data_in_usaus_states\n",
      "CSV file read: rearc_usa_hospital_beds.csv for table: rearc_usa_hospital_beds\n",
      "CSV file read: static_datasets_countrycodecountrycode.csv for table: static_datasets_countrycodecountrycode\n",
      "CSV file read: static_datasets_countypopulationcountypopulation.csv for table: static_datasets_countypopulationcountypopulation\n",
      "CSV file read: static_datasets_state_abvstate_abv.csv for table: static_datasets_state_abvstate_abv\n",
      "Table: enigma_jhud\n",
      "   fips admin2 province_state country_region          last_update  latitude  \\\n",
      "0   NaN    NaN          Anhui          China  2020-01-22T17:00:00    31.826   \n",
      "1   NaN    NaN        Beijing          China  2020-01-22T17:00:00    40.182   \n",
      "2   NaN    NaN      Chongqing          China  2020-01-22T17:00:00    30.057   \n",
      "3   NaN    NaN         Fujian          China  2020-01-22T17:00:00    26.079   \n",
      "4   NaN    NaN          Gansu          China  2020-01-22T17:00:00    36.061   \n",
      "\n",
      "   longitude  confirmed  deaths  recovered  active combined_key partition_0  \n",
      "0    117.226        1.0     NaN        NaN     NaN       \"Anhui         csv  \n",
      "1    116.414       14.0     NaN        NaN     NaN     \"Beijing         csv  \n",
      "2    107.874        6.0     NaN        NaN     NaN   \"Chongqing         csv  \n",
      "3    117.987        1.0     NaN        NaN     NaN      \"Fujian         csv  \n",
      "4    103.834        NaN     NaN        NaN     NaN       \"Gansu         csv  \n",
      "\n",
      "Table: nytimes_data_in_usa_countyus_county\n",
      "         date     county       state     fips  cases  deaths\n",
      "0  2020-01-21  Snohomish  Washington  53061.0    1.0     0.0\n",
      "1  2020-01-22  Snohomish  Washington  53061.0    1.0     0.0\n",
      "2  2020-01-23  Snohomish  Washington  53061.0    1.0     0.0\n",
      "3  2020-01-24       Cook    Illinois  17031.0    1.0     0.0\n",
      "4  2020-01-24  Snohomish  Washington  53061.0    1.0     0.0\n",
      "\n",
      "Table: covid_19_testing_data_states_dailystates_daily\n",
      "       date state  positive  probablecases   negative  pending  \\\n",
      "0  20210220    UT    366034            NaN  1507875.0      NaN   \n",
      "1  20210220    VA    561812       117662.0        NaN    195.0   \n",
      "2  20210220    VI      2575            NaN    43564.0    108.0   \n",
      "3  20210220    VT     14359          411.0   309335.0      NaN   \n",
      "4  20210220    WA    332904        17485.0        NaN      NaN   \n",
      "\n",
      "     totaltestresultssource  totaltestresults  hospitalizedcurrently  \\\n",
      "0           totalTestsViral           2788882                  260.0   \n",
      "1  totalTestEncountersViral           5728208                 1594.0   \n",
      "2                    posNeg             46139                    NaN   \n",
      "3           totalTestsViral           1009285                   39.0   \n",
      "4  totalTestEncountersViral           5048054                  608.0   \n",
      "\n",
      "   hospitalizedcumulative  ...  dataqualitygrade  deathincrease  \\\n",
      "0                 14421.0  ...               NaN            8.0   \n",
      "1                 23436.0  ...               NaN           99.0   \n",
      "2                     NaN  ...               NaN            0.0   \n",
      "3                     NaN  ...               NaN            3.0   \n",
      "4                 18969.0  ...               NaN           19.0   \n",
      "\n",
      "   hospitalizedincrease                                      hash  \\\n",
      "0                  39.0  70f3e22ea3d10f99d5f3c09c55ba95fa1b8aaabb   \n",
      "1                  67.0  75d813bab6075e36b3ed1d3bbbfe18f6692e3959   \n",
      "2                   0.0  7ca160663de572688bb23d17943b6f59863f5fd0   \n",
      "3                   0.0  5156647b94cb2e59c9e4e26be1943e4827a99f13   \n",
      "4                  35.0  8150e925fc2fb429eeb347109e52f7b99ba00f17   \n",
      "\n",
      "   commercialscore negativeregularscore negativescore positivescore  score  \\\n",
      "0              0.0                  0.0           0.0           0.0    0.0   \n",
      "1              0.0                  0.0           0.0           0.0    0.0   \n",
      "2              0.0                  0.0           0.0           0.0    0.0   \n",
      "3              0.0                  0.0           0.0           0.0    0.0   \n",
      "4              0.0                  0.0           0.0           0.0    0.0   \n",
      "\n",
      "   grade  \n",
      "0    NaN  \n",
      "1    NaN  \n",
      "2    NaN  \n",
      "3    NaN  \n",
      "4    NaN  \n",
      "\n",
      "[5 rows x 56 columns]\n",
      "\n",
      "Table: covid_19_testing_data_us_dailyus_daily\n",
      "       date  states    positive    negative  pending  hospitalizedcurrently  \\\n",
      "0  20210307      56  28755524.0  74579770.0  11808.0                40212.0   \n",
      "1  20210306      56  28714259.0  74449356.0  11783.0                41401.0   \n",
      "2  20210305      56  28654639.0  74307155.0  12213.0                42541.0   \n",
      "3  20210304      56  28585852.0  74035238.0  12405.0                44172.0   \n",
      "4  20210303      56  28520365.0  73857281.0  11778.0                45462.0   \n",
      "\n",
      "   hospitalizedcumulative  inicucurrently  inicucumulative  \\\n",
      "0                878613.0          8137.0          45475.0   \n",
      "1                877887.0          8409.0          45453.0   \n",
      "2                877384.0          8634.0          45373.0   \n",
      "3                874603.0          8970.0          45293.0   \n",
      "4                873073.0          9359.0          45214.0   \n",
      "\n",
      "   onventilatorcurrently  ...          lastmodified recovered  total  posneg  \\\n",
      "0                 2801.0  ...  2021-03-07T24:00:00Z       NaN      0       0   \n",
      "1                 2811.0  ...  2021-03-06T24:00:00Z       NaN      0       0   \n",
      "2                 2889.0  ...  2021-03-05T24:00:00Z       NaN      0       0   \n",
      "3                 2973.0  ...  2021-03-04T24:00:00Z       NaN      0       0   \n",
      "4                 3094.0  ...  2021-03-03T24:00:00Z       NaN      0       0   \n",
      "\n",
      "   deathincrease hospitalizedincrease  negativeincrease  positiveincrease  \\\n",
      "0            839                  726            130414             41265   \n",
      "1           1674                  503            142201             59620   \n",
      "2           2221                 2781            271917             68787   \n",
      "3           1743                 1530            177957             65487   \n",
      "4           2449                 2172            267001             66836   \n",
      "\n",
      "   totaltestresultsincrease                                      hash  \n",
      "0                   1156241  8b26839690cd05c0cef69cb9ed85641a76b5e78e  \n",
      "1                   1409138  d0c0482ea549c9d5c04a7c86acb6fc6a8095a592  \n",
      "2                   1744417  a35ea4289cec4bb55c9f29ae04ec0fd5ac4e0222  \n",
      "3                   1590984  a19ad6379a653834cbda3093791ad2c3b9fab5ff  \n",
      "4                   1406795  9e1d2afda1b0ec243060d6f68a7134d011c0cb2a  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Table: covid_19_testing_data_us_total_latestus_total_latest\n",
      "   positive  negative  pending  hospitalizedcurrently  hospitalizedcumulative  \\\n",
      "0   1061101   5170081     2775                  53793                  111955   \n",
      "\n",
      "   inicucurrently  inicucumulative  onventilatorcurrently  \\\n",
      "0            9486             4192                   4712   \n",
      "\n",
      "   onventilatorcumulative  recovered  \\\n",
      "0                     373     153947   \n",
      "\n",
      "                                       hash              lastmodified  death  \\\n",
      "0  95064ba29ccbc20dbec397033dfe4b1f45137c99  2020-05-01T09:12:31.891Z  57266   \n",
      "\n",
      "   hospitalized    total  totaltestresults   posneg             notes  \n",
      "0        111955  6233957           6231182  6231182  \"NOTE: \"\"total\"\"  \n",
      "\n",
      "Table: nytimes_data_in_usaus_states\n",
      "         date       state  fips  cases  deaths\n",
      "0  2020-01-21  Washington    53      1       0\n",
      "1  2020-01-22  Washington    53      1       0\n",
      "2  2020-01-23  Washington    53      1       0\n",
      "3  2020-01-24    Illinois    17      1       0\n",
      "4  2020-01-24  Washington    53      1       0\n",
      "\n",
      "Table: rearc_usa_hospital_beds\n",
      "   objectid                                      hospital_name hospital_type  \\\n",
      "0         1  Phoenix VA Health Care System (AKA Carl T Hayd...   VA Hospital   \n",
      "1         2             Southern Arizona VA Health Care System   VA Hospital   \n",
      "2         3           VA Central California Health Care System   VA Hospital   \n",
      "3         4  VA Connecticut Healthcare System - West Haven ...   VA Hospital   \n",
      "4         5                       Wilmington VA Medical Center   VA Hospital   \n",
      "\n",
      "               hq_address hq_address1     hq_city hq_state  hq_zip_code  \\\n",
      "0  650 E Indian School Rd         NaN     Phoenix       AZ        85012   \n",
      "1          3601 S 6th Ave         NaN      Tucson       AZ        85723   \n",
      "2      2615 E Clinton Ave         NaN      Fresno       CA        93703   \n",
      "3        950 Campbell Ave         NaN  West Haven       CT         6516   \n",
      "4       1601 Kirkwood Hwy         NaN  Wilmington       DE        19805   \n",
      "\n",
      "  county_name   state_name  ...  num_licensed_beds  num_staffed_beds  \\\n",
      "0    Maricopa      Arizona  ...              129.0             129.0   \n",
      "1        Pima      Arizona  ...              295.0             295.0   \n",
      "2      Fresno   California  ...               57.0              57.0   \n",
      "3   New Haven  Connecticut  ...              216.0             216.0   \n",
      "4  New Castle     Delaware  ...               60.0              60.0   \n",
      "\n",
      "   num_icu_beds  adult_icu_beds  pedi_icu_beds  bed_utilization  \\\n",
      "0             0               0            NaN              NaN   \n",
      "1             2               2            NaN              NaN   \n",
      "2             2               2            NaN              NaN   \n",
      "3             1               1            NaN              NaN   \n",
      "4             0               0            NaN              NaN   \n",
      "\n",
      "   avg_ventilator_usage  potential_increase_in_bed_capac   latitude  \\\n",
      "0                   0.0                                0  33.495498   \n",
      "1                   2.0                                0  32.181263   \n",
      "2                   2.0                                0  36.773324   \n",
      "3                   2.0                                0  41.284400   \n",
      "4                   1.0                                0  39.740206   \n",
      "\n",
      "   longtitude  \n",
      "0 -112.066157  \n",
      "1 -110.965885  \n",
      "2 -119.779742  \n",
      "3  -72.957610  \n",
      "4  -75.606532  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Table: static_datasets_countrycodecountrycode\n",
      "          country alpha-2 code alpha-3 code  numeric code  latitude  longitude\n",
      "0     Afghanistan           AF          AFG           4.0   33.0000       65.0\n",
      "1         Albania           AL          ALB           8.0   41.0000       20.0\n",
      "2         Algeria           DZ          DZA          12.0   28.0000        3.0\n",
      "3  American Samoa           AS          ASM          16.0  -14.3333     -170.0\n",
      "4         Andorra           AD          AND          20.0   42.5000        1.6\n",
      "\n",
      "Table: static_datasets_countypopulationcountypopulation\n",
      "               id   id2   county    state  population estimate 2018\n",
      "0  0500000US01001  1001  Autauga  Alabama                     55601\n",
      "1  0500000US01003  1003  Baldwin  Alabama                    218022\n",
      "2  0500000US01005  1005  Barbour  Alabama                     24881\n",
      "3  0500000US01007  1007     Bibb  Alabama                     22400\n",
      "4  0500000US01009  1009   Blount  Alabama                     57840\n",
      "\n",
      "Table: static_datasets_state_abvstate_abv\n",
      "       col0          col1\n",
      "0     State  Abbreviation\n",
      "1   Alabama            AL\n",
      "2    Alaska            AK\n",
      "3   Arizona            AZ\n",
      "4  Arkansas            AR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table_data = {}  # Dictionary to store table data\n",
    "\n",
    "table_names = [\"enigma_jhud\", \"nytimes_data_in_usa_countyus_county\",\"covid_19_testing_data_states_dailystates_daily\",\"covid_19_testing_data_us_dailyus_daily\",\"covid_19_testing_data_us_total_latestus_total_latest\",\"nytimes_data_in_usaus_states\",\"rearc_usa_hospital_beds\",\"static_datasets_countrycodecountrycode\",\"static_datasets_countypopulationcountypopulation\",\"static_datasets_state_abvstate_abv\"]\n",
    "\n",
    "for table_name in table_names:\n",
    "    file_name = table_name + \".csv\"\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    table_data[table_name] = pd.read_csv(file_name)\n",
    "    print(f\"CSV file read: {file_name} for table: {table_name}\")\n",
    "\n",
    "# Access the table data using table names as keys\n",
    "for table_name, data in table_data.items():\n",
    "    # Perform operations on the table data\n",
    "    print(f\"Table: {table_name}\")\n",
    "    print(data.head())  # Example: Print the first few rows of the table\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "220a9ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the downloaded CSV file into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9cefd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "enigma_jhud_data = table_data[\"enigma_jhud\"]\n",
    "nytimes_data_usa_county = table_data[\"nytimes_data_in_usa_countyus_county\"]\n",
    "covid_testing_states_daily = table_data[\"covid_19_testing_data_states_dailystates_daily\"]\n",
    "covid_19_testing_data_us = table_data[\"covid_19_testing_data_us_dailyus_daily\"]\n",
    "covid_19_testing_data_us_total_latest = table_data[\"covid_19_testing_data_us_total_latestus_total_latest\"]\n",
    "nytimes_data_in_usa_states = table_data[\"nytimes_data_in_usaus_states\"]\n",
    "rearc_usa_hospital_beds = table_data[\"rearc_usa_hospital_beds\"]\n",
    "static_datasets_countrycode = table_data[\"static_datasets_countrycodecountrycode\"]\n",
    "static_datasets_countypopulation = table_data[\"static_datasets_countypopulationcountypopulation\"]\n",
    "static_datasets_state_abv = table_data[\"static_datasets_state_abvstate_abv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2ca4766",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col0</th>\n",
       "      <th>col1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State</td>\n",
       "      <td>Abbreviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       col0          col1\n",
       "0     State  Abbreviation\n",
       "1   Alabama            AL\n",
       "2    Alaska            AK\n",
       "3   Arizona            AZ\n",
       "4  Arkansas            AR"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_datasets_state_abv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4b4b49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col0           State\n",
       "col1    Abbreviation\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_header = static_datasets_state_abv.iloc[0] \n",
    "new_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "899b9427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Abbreviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0       State Abbreviation\n",
       "1     Alabama           AL\n",
       "2      Alaska           AK\n",
       "3     Arizona           AZ\n",
       "4    Arkansas           AR\n",
       "5  California           CA"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_datasets_state_abv = static_datasets_state_abv[1:]\n",
    "static_datasets_state_abv.columns = new_header\n",
    "static_datasets_state_abv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5147a0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "      <th>date</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>hospitalizedcurrently</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>hospitalizeddischarged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6110</th>\n",
       "      <td>72.0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20210123</td>\n",
       "      <td>90073</td>\n",
       "      <td>305972.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6111</th>\n",
       "      <td>72.0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20210122</td>\n",
       "      <td>89282</td>\n",
       "      <td>305972.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6112</th>\n",
       "      <td>72.0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20210121</td>\n",
       "      <td>88728</td>\n",
       "      <td>305972.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6113</th>\n",
       "      <td>72.0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20210120</td>\n",
       "      <td>88513</td>\n",
       "      <td>305972.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114</th>\n",
       "      <td>72.0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20210119</td>\n",
       "      <td>88373</td>\n",
       "      <td>305972.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fips province_state country_region  confirmed  deaths  recovered  \\\n",
       "6110  72.0    Puerto Rico             US       51.0     2.0        0.0   \n",
       "6111  72.0    Puerto Rico             US       51.0     2.0        0.0   \n",
       "6112  72.0    Puerto Rico             US       51.0     2.0        0.0   \n",
       "6113  72.0    Puerto Rico             US       51.0     2.0        0.0   \n",
       "6114  72.0    Puerto Rico             US       51.0     2.0        0.0   \n",
       "\n",
       "      active      date  positive  negative  hospitalizedcurrently  \\\n",
       "6110     0.0  20210123     90073  305972.0                  325.0   \n",
       "6111     0.0  20210122     89282  305972.0                  341.0   \n",
       "6112     0.0  20210121     88728  305972.0                  344.0   \n",
       "6113     0.0  20210120     88513  305972.0                  331.0   \n",
       "6114     0.0  20210119     88373  305972.0                  351.0   \n",
       "\n",
       "      hospitalized  hospitalizeddischarged  \n",
       "6110           NaN                     NaN  \n",
       "6111           NaN                     NaN  \n",
       "6112           NaN                     NaN  \n",
       "6113           NaN                     NaN  \n",
       "6114           NaN                     NaN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factcovid_1 = enigma_jhud_data[['fips', 'province_state', 'country_region', 'confirmed', 'deaths', 'recovered', 'active',]]\n",
    "factcovid_2 = covid_testing_states_daily[['fips','date','positive','negative','hospitalizedcurrently','hospitalized','hospitalizeddischarged']]\n",
    "factCovid = pd.merge(factcovid_1,factcovid_2, on = 'fips', how = 'inner')\n",
    "factCovid.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "533e2541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fips', 'admin2', 'province_state', 'country_region', 'last_update',\n",
       "       'latitude', 'longitude', 'confirmed', 'deaths', 'recovered', 'active',\n",
       "       'combined_key', 'partition_0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enigma_jhud_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10d05b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'county', 'state', 'fips', 'cases', 'deaths'], dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nytimes_data_usa_county.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8165709a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>31.826</td>\n",
       "      <td>117.226</td>\n",
       "      <td>New York City</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>31.826</td>\n",
       "      <td>117.226</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Rhode Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>31.826</td>\n",
       "      <td>117.226</td>\n",
       "      <td>New York City</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>31.826</td>\n",
       "      <td>117.226</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Rhode Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>31.826</td>\n",
       "      <td>117.226</td>\n",
       "      <td>New York City</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips province_state country_region  latitude  longitude         county  \\\n",
       "0   NaN          Anhui          China    31.826    117.226  New York City   \n",
       "1   NaN          Anhui          China    31.826    117.226        Unknown   \n",
       "2   NaN          Anhui          China    31.826    117.226  New York City   \n",
       "3   NaN          Anhui          China    31.826    117.226        Unknown   \n",
       "4   NaN          Anhui          China    31.826    117.226  New York City   \n",
       "\n",
       "          state  \n",
       "0      New York  \n",
       "1  Rhode Island  \n",
       "2      New York  \n",
       "3  Rhode Island  \n",
       "4      New York  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_region_1 = enigma_jhud_data[['fips', 'province_state', 'country_region','latitude', 'longitude']]\n",
    "dim_region_2 = nytimes_data_usa_county[['county', 'state', 'fips']]\n",
    "dimRegion = pd.merge(dim_region_1, dim_region_2, on = 'fips', how = 'inner')\n",
    "dimRegion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa1b39f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['objectid', 'hospital_name', 'hospital_type', 'hq_address',\n",
       "       'hq_address1', 'hq_city', 'hq_state', 'hq_zip_code', 'county_name',\n",
       "       'state_name', 'state_fips', 'cnty_fips', 'fips', 'num_licensed_beds',\n",
       "       'num_staffed_beds', 'num_icu_beds', 'adult_icu_beds', 'pedi_icu_beds',\n",
       "       'bed_utilization', 'avg_ventilator_usage',\n",
       "       'potential_increase_in_bed_capac', 'latitude', 'longtitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearc_usa_hospital_beds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03c8ee55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>state_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longtitude</th>\n",
       "      <th>hq_address</th>\n",
       "      <th>hospital_name</th>\n",
       "      <th>hospital_type</th>\n",
       "      <th>hq_city</th>\n",
       "      <th>hq_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4013</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>33.495498</td>\n",
       "      <td>-112.066157</td>\n",
       "      <td>650 E Indian School Rd</td>\n",
       "      <td>Phoenix VA Health Care System (AKA Carl T Hayd...</td>\n",
       "      <td>VA Hospital</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4019</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>32.181263</td>\n",
       "      <td>-110.965885</td>\n",
       "      <td>3601 S 6th Ave</td>\n",
       "      <td>Southern Arizona VA Health Care System</td>\n",
       "      <td>VA Hospital</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6019</td>\n",
       "      <td>California</td>\n",
       "      <td>36.773324</td>\n",
       "      <td>-119.779742</td>\n",
       "      <td>2615 E Clinton Ave</td>\n",
       "      <td>VA Central California Health Care System</td>\n",
       "      <td>VA Hospital</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9009</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>41.284400</td>\n",
       "      <td>-72.957610</td>\n",
       "      <td>950 Campbell Ave</td>\n",
       "      <td>VA Connecticut Healthcare System - West Haven ...</td>\n",
       "      <td>VA Hospital</td>\n",
       "      <td>West Haven</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>39.740206</td>\n",
       "      <td>-75.606532</td>\n",
       "      <td>1601 Kirkwood Hwy</td>\n",
       "      <td>Wilmington VA Medical Center</td>\n",
       "      <td>VA Hospital</td>\n",
       "      <td>Wilmington</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fips   state_name   latitude  longtitude              hq_address  \\\n",
       "0   4013      Arizona  33.495498 -112.066157  650 E Indian School Rd   \n",
       "1   4019      Arizona  32.181263 -110.965885          3601 S 6th Ave   \n",
       "2   6019   California  36.773324 -119.779742      2615 E Clinton Ave   \n",
       "3   9009  Connecticut  41.284400  -72.957610        950 Campbell Ave   \n",
       "4  10003     Delaware  39.740206  -75.606532       1601 Kirkwood Hwy   \n",
       "\n",
       "                                       hospital_name hospital_type  \\\n",
       "0  Phoenix VA Health Care System (AKA Carl T Hayd...   VA Hospital   \n",
       "1             Southern Arizona VA Health Care System   VA Hospital   \n",
       "2           VA Central California Health Care System   VA Hospital   \n",
       "3  VA Connecticut Healthcare System - West Haven ...   VA Hospital   \n",
       "4                       Wilmington VA Medical Center   VA Hospital   \n",
       "\n",
       "      hq_city hq_state  \n",
       "0     Phoenix       AZ  \n",
       "1      Tucson       AZ  \n",
       "2      Fresno       CA  \n",
       "3  West Haven       CT  \n",
       "4  Wilmington       DE  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_hospital = rearc_usa_hospital_beds[[ 'fips','state_name','latitude', 'longtitude','hq_address','hospital_name', 'hospital_type','hq_city', 'hq_state']]\n",
    "dim_hospital.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f9b03a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>20210220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>20210220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>20210220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>20210220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.0</td>\n",
       "      <td>20210220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips      date\n",
       "0  49.0  20210220\n",
       "1  51.0  20210220\n",
       "2  78.0  20210220\n",
       "3  50.0  20210220\n",
       "4  53.0  20210220"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_date = covid_testing_states_daily[['fips','date']]\n",
    "dim_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9dd6fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips       date\n",
       "0  49.0 2021-02-20\n",
       "1  51.0 2021-02-20\n",
       "2  78.0 2021-02-20\n",
       "3  50.0 2021-02-20\n",
       "4  53.0 2021-02-20"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_date['date'] = pd.to_datetime(dim_date['date'],format = '%Y%m%d')\n",
    "dim_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f890212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>dayOfWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips       date  year  month  dayOfWeek\n",
       "0  49.0 2021-02-20  2021      2          5\n",
       "1  51.0 2021-02-20  2021      2          5\n",
       "2  78.0 2021-02-20  2021      2          5\n",
       "3  50.0 2021-02-20  2021      2          5\n",
       "4  53.0 2021-02-20  2021      2          5"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_date['year'] = dim_date['date'].dt.year\n",
    "dim_date['month'] = dim_date['date'].dt.month\n",
    "dim_date['dayOfWeek'] = dim_date['date'].dt.dayofweek\n",
    "dim_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "312ab765",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_date_csv = dim_date.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "61ad7899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '3FGN76C2SZ2PZ2ZS',\n",
       "  'HostId': 'i0ZdcYkiJ3q1dDbMIlgOjrMHEa0Ey872IqiEOiDQVSaMnAxVXGMyxnmzyAqDFonEHQ9c1BKOWIg=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'i0ZdcYkiJ3q1dDbMIlgOjrMHEa0Ey872IqiEOiDQVSaMnAxVXGMyxnmzyAqDFonEHQ9c1BKOWIg=',\n",
       "   'x-amz-request-id': '3FGN76C2SZ2PZ2ZS',\n",
       "   'date': 'Wed, 24 May 2023 20:22:35 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"95999819250ac7ff43676bd7179406ea\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 1},\n",
       " 'ETag': '\"95999819250ac7ff43676bd7179406ea\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a session using your AWS credentials\n",
    "session = boto3.Session(aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY)\n",
    "\n",
    "# Create an S3 client\n",
    "s3_client = session.client('s3')\n",
    "\n",
    "# Define the S3 bucket and file path\n",
    "bucket_name = 'meenakshi-test-bucket'\n",
    "file_path = 'output/dim_date_csv'\n",
    "\n",
    "# Upload the data to S3\n",
    "s3_client.put_object(Body=dim_date_csv, Bucket=bucket_name, Key=file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dbf04c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File output/dim_date.csv already exists. Deleting it...\n",
      "File output/dim_hospital.csv already exists. Deleting it...\n",
      "File output/factCovid.csv already exists. Deleting it...\n"
     ]
    }
   ],
   "source": [
    "def upload_dataframe_to_s3(dataframe, file_path):\n",
    "    # Convert DataFrame to CSV\n",
    "    csv_data = dataframe.to_csv(index=False)\n",
    "\n",
    "    # Create a session using your AWS credentials\n",
    "    session = boto3.Session(aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY)\n",
    "\n",
    "    # Create an S3 client\n",
    "    s3_client = session.client('s3')\n",
    "\n",
    "    # Define the S3 bucket and file path\n",
    "    bucket_name = 'meenakshi-test-bucket'\n",
    "    key = file_path\n",
    "\n",
    "    # Check if the file already exists in the bucket\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=key)\n",
    "        print(f'File {key} already exists. Deleting it...')\n",
    "        s3_client.delete_object(Bucket=bucket_name, Key=key)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Upload the data to S3\n",
    "    s3_client.put_object(Body=csv_data, Bucket=bucket_name, Key=key)\n",
    "\n",
    "# Define a list of file paths for different CSV files\n",
    "file_paths = ['output/dim_date.csv', 'output/dim_hospital.csv', 'output/factCovid.csv', 'output/dimRegion.csv']\n",
    "dim_dataframe_dict = [dim_date,dim_hospital,dimRegion,factCovid]\n",
    "\n",
    "# Upload each DataFrame to S3 in a loop\n",
    "for path, dataframe in zip(file_paths, dim_dataframe_dict):\n",
    "    upload_dataframe_to_s3(dataframe, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "66453ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>dayOfWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.0</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips       date  year  month  dayOfWeek\n",
       "0  49.0 2021-02-20  2021      2          5\n",
       "1  51.0 2021-02-20  2021      2          5\n",
       "2  78.0 2021-02-20  2021      2          5\n",
       "3  50.0 2021-02-20  2021      2          5\n",
       "4  53.0 2021-02-20  2021      2          5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get schema for the dim and fact tables\n",
    "dim_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cc90cf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fipsdateyearmonthdayOfWeek\n"
     ]
    }
   ],
   "source": [
    "dimDatesql = pd.io.sql.get_schema(dim_date.reset_index(),'dim_date')\n",
    "print(''.join(dim_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cf715b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"dimDate\" (\n",
      "\"fips\" INTEGER,\n",
      "  \"state_name\" TEXT,\n",
      "  \"latitude\" REAL,\n",
      "  \"longtitude\" REAL,\n",
      "  \"hq_address\" TEXT,\n",
      "  \"hospital_name\" TEXT,\n",
      "  \"hospital_type\" TEXT,\n",
      "  \"hq_city\" TEXT,\n",
      "  \"hq_state\" TEXT\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the SQL schema of the subset DataFrame\n",
    "schema = pd.io.sql.get_schema(dim_hospital, 'dimDate')\n",
    "\n",
    "# Print the SQL schema\n",
    "print(schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed561a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"dim_date\" (\n",
      "\"fips\" REAL,\n",
      "  \"date\" TIMESTAMP,\n",
      "  \"year\" INTEGER,\n",
      "  \"month\" INTEGER,\n",
      "  \"dayOfWeek\" INTEGER\n",
      ")\n",
      "\n",
      "\n",
      "CREATE TABLE \"dim_hospital\" (\n",
      "\"fips\" INTEGER,\n",
      "  \"state_name\" TEXT,\n",
      "  \"latitude\" REAL,\n",
      "  \"longtitude\" REAL,\n",
      "  \"hq_address\" TEXT,\n",
      "  \"hospital_name\" TEXT,\n",
      "  \"hospital_type\" TEXT,\n",
      "  \"hq_city\" TEXT,\n",
      "  \"hq_state\" TEXT\n",
      ")\n",
      "\n",
      "\n",
      "CREATE TABLE \"factCovid\" (\n",
      "\"fips\" REAL,\n",
      "  \"province_state\" TEXT,\n",
      "  \"country_region\" TEXT,\n",
      "  \"confirmed\" REAL,\n",
      "  \"deaths\" REAL,\n",
      "  \"recovered\" REAL,\n",
      "  \"active\" REAL,\n",
      "  \"date\" INTEGER,\n",
      "  \"positive\" INTEGER,\n",
      "  \"negative\" REAL,\n",
      "  \"hospitalizedcurrently\" REAL,\n",
      "  \"hospitalized\" REAL,\n",
      "  \"hospitalizeddischarged\" REAL\n",
      ")\n",
      "\n",
      "\n",
      "CREATE TABLE \"dimRegion\" (\n",
      "\"fips\" REAL,\n",
      "  \"province_state\" TEXT,\n",
      "  \"country_region\" TEXT,\n",
      "  \"latitude\" REAL,\n",
      "  \"longitude\" REAL,\n",
      "  \"county\" TEXT,\n",
      "  \"state\" TEXT\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of DataFrames\n",
    "dataframes = [dim_date, dim_hospital, factCovid, dimRegion]\n",
    "table_names = ['dim_date', 'dim_hospital', 'factCovid', 'dimRegion']\n",
    "\n",
    "# Loop through the DataFrames\n",
    "for df, table_name in zip(dataframes, table_names):\n",
    "    # Get the SQL schema of the subset DataFrame\n",
    "    schema = pd.io.sql.get_schema(df, table_name)\n",
    "\n",
    "    # Print the SQL schema\n",
    "    print(schema)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4bfd1e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: redshift_connector in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (2.0.910)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from redshift_connector) (2021.3)\n",
      "Requirement already satisfied: scramp<1.5.0,>=1.2.0 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from redshift_connector) (1.4.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from redshift_connector) (21.3)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.12.201 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from redshift_connector) (1.29.139)\n",
      "Requirement already satisfied: lxml>=4.6.5 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from redshift_connector) (4.8.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.7.0 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from redshift_connector) (4.11.1)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.9.201 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from redshift_connector) (1.26.139)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from redshift_connector) (61.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from redshift_connector) (2.27.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.7.0->redshift_connector) (2.3.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from boto3<2.0.0,>=1.9.201->redshift_connector) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from boto3<2.0.0,>=1.9.201->redshift_connector) (0.6.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from botocore<2.0.0,>=1.12.201->redshift_connector) (1.26.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from botocore<2.0.0,>=1.12.201->redshift_connector) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.12.201->redshift_connector) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->redshift_connector) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->redshift_connector) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->redshift_connector) (3.3)\n",
      "Requirement already satisfied: asn1crypto>=1.5.1 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from scramp<1.5.0,>=1.2.0->redshift_connector) (1.5.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dpsmv\\anaconda3\\lib\\site-packages (from packaging->redshift_connector) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dpsmv\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dpsmv\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dpsmv\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dpsmv\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dpsmv\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dpsmv\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install redshift_connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7733f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redshift_connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "89e21eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.6-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dpsmv\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dpsmv\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dpsmv\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dpsmv\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dpsmv\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dpsmv\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dpsmv\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19cfadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redshift_connector\n",
    "\n",
    "conn = redshift_connector.connect(\n",
    "    host='redshift-cluster-1.cdoeoearcpxt.us-east-1.redshift.amazonaws.com',\n",
    "    port=5439,\n",
    "    database='dev',\n",
    "    user='awsuser',\n",
    "    password='Meenakshi1',\n",
    "    timeout=120\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95bbc879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto commit to refelect the cahnges to the redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b139f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a55a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cursor used for exceution of queries\n",
    "cursor = redshift_connector.Cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fdb450c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<redshift_connector.cursor.Cursor at 0x290c4ed5fa0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE \"dim_date\" (\n",
    "\"fips\" REAL,\n",
    "  \"date\" TIMESTAMP,\n",
    "  \"year\" INTEGER,\n",
    "  \"month\" INTEGER,\n",
    "  \"dayOfWeek\" INTEGER\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7eae7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<redshift_connector.cursor.Cursor at 0x290c4ed5fa0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE \"dim_hospital\" (\n",
    "\"fips\" INTEGER,\n",
    "  \"state_name\" TEXT,\n",
    "  \"latitude\" REAL,\n",
    "  \"longtitude\" REAL,\n",
    "  \"hq_address\" TEXT,\n",
    "  \"hospital_name\" TEXT,\n",
    "  \"hospital_type\" TEXT,\n",
    "  \"hq_city\" TEXT,\n",
    "  \"hq_state\" TEXT\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8f85a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<redshift_connector.cursor.Cursor at 0x290c4ed5fa0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE \"factCovid\" (\n",
    "\"fips\" REAL,\n",
    "  \"province_state\" TEXT,\n",
    "  \"country_region\" TEXT,\n",
    "  \"confirmed\" REAL,\n",
    "  \"deaths\" REAL,\n",
    "  \"recovered\" REAL,\n",
    "  \"active\" REAL,\n",
    "  \"date\" INTEGER,\n",
    "  \"positive\" INTEGER,\n",
    "  \"negative\" REAL,\n",
    "  \"hospitalizedcurrently\" REAL,\n",
    "  \"hospitalized\" REAL,\n",
    "  \"hospitalizeddischarged\" REAL\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93cca514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<redshift_connector.cursor.Cursor at 0x290c4ed5fa0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE \"dimRegion\" (\n",
    "\"fips\" REAL,\n",
    "  \"province_state\" TEXT,\n",
    "  \"country_region\" TEXT,\n",
    "  \"latitude\" REAL,\n",
    "  \"longitude\" REAL,\n",
    "  \"county\" TEXT,\n",
    "  \"state\" TEXT\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc964c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<redshift_connector.cursor.Cursor at 0x2756cbb5ee0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "copy dim_date from 's3://meenakshi-test-bucket/output/dim_date_csv'\n",
    "CREDENTIALS 'aws_iam_role=arn:aws:iam::591034249457:role/service-role/AmazonRedshift-CommandsAccessRole-20230525T105017'\n",
    "delimiter ','\n",
    "region 'us-east-1'\n",
    "IGNOREHEADER 1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41ff84f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "{'S': 'ERROR', 'C': 'XX000', 'M': 'Cannot COPY into nonexistent table dim_date', 'F': '../src/sys/compression_analyzer.cpp', 'L': '520', 'R': 'XenGetLoadTableId'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;43mcopy dim_date from \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms3://meenakshi-test-bucket/output/dim_date_csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;43mCREDENTIALS \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maws_iam_role=arn:aws:iam::591034249457:role/service-role/AmazonRedshift-CommandsAccessRole-20230525T105017\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;43mdelimiter \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;43mregion \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mus-east-1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;43mIGNOREHEADER 1\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\redshift_connector\\cursor.py:240\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, operation, args, stream, merge_socket_read)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin transaction\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39mmerge_socket_read \u001b[38;5;241m=\u001b[39m merge_socket_read\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\redshift_connector\\core.py:1783\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, cursor, operation, vals)\u001b[0m\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_messages_merge_socket_read(cursor)\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1783\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\redshift_connector\\core.py:1969\u001b[0m, in \u001b[0;36mConnection.handle_messages\u001b[1;34m(self, cursor)\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage_types[code](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read(data_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m4\u001b[39m), cursor)\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror\n",
      "\u001b[1;31mProgrammingError\u001b[0m: {'S': 'ERROR', 'C': 'XX000', 'M': 'Cannot COPY into nonexistent table dim_date', 'F': '../src/sys/compression_analyzer.cpp', 'L': '520', 'R': 'XenGetLoadTableId'}"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "copy dimRegion from 's3://meenakshi-test-bucket/output/dim_date_csv'\n",
    "CREDENTIALS 'aws_iam_role=arn:aws:iam::591034249457:role/service-role/AmazonRedshift-CommandsAccessRole-20230525T105017'\n",
    "delimiter ','\n",
    "region 'us-east-1'\n",
    "IGNOREHEADER 1\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "copy dim_hospital from 's3://meenakshi-test-bucket/output/dim_date_csv'\n",
    "CREDENTIALS 'aws_iam_role=arn:aws:iam::591034249457:role/service-role/AmazonRedshift-CommandsAccessRole-20230525T105017'\n",
    "delimiter ','\n",
    "region 'us-east-1'\n",
    "IGNOREHEADER 1\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "copy factCovid from 's3://meenakshi-test-bucket/output/dim_date_csv'\n",
    "CREDENTIALS 'aws_iam_role=arn:aws:iam::591034249457:role/service-role/AmazonRedshift-CommandsAccessRole-20230525T105017'\n",
    "delimiter ','\n",
    "region 'us-east-1'\n",
    "IGNOREHEADER 1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be1db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
